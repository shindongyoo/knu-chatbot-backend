import os
import re
import faiss
import pickle
from dotenv import load_dotenv
from langchain_community.vectorstores import FAISS as LangChainFAISS
from langchain_openai import OpenAIEmbeddings
from langchain_core.documents import Document
from langchain_community.docstore.in_memory import InMemoryDocstore
from app.database import chatbot_db

load_dotenv()

embeddings = OpenAIEmbeddings(
    model="text-embedding-3-small",  # <-- "ada-002"ì—ì„œ ë³€ê²½!
    openai_api_key=os.getenv("OPENAI_API_KEY")
)

def load_vector_db_manually(folder_path, index_name):
    faiss_path = os.path.join(folder_path, f"{index_name}.faiss")
    pkl_path = os.path.join(folder_path, f"{index_name}.pkl")
    if not os.path.exists(faiss_path) or not os.path.exists(pkl_path):
        raise FileNotFoundError(f"'{folder_path}'ì—ì„œ DB íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {index_name}")
    index = faiss.read_index(faiss_path)
    with open(pkl_path, "rb") as f:
        docs_data = pickle.load(f)
    documents = [Document(page_content=doc.pop('content', ''), metadata=doc) for doc in docs_data]
    docstore = InMemoryDocstore({str(i): doc for i, doc in enumerate(documents)})
    index_to_docstore_id = {i: str(i) for i in range(len(documents))}
    return LangChainFAISS(embedding_function=embeddings, index=index, docstore=docstore, index_to_docstore_id=index_to_docstore_id)

# Vector DB ë¡œë”©
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
notices_title_db = None
notices_content_db = None
jobs_db = None

try:
    NOTICES_DB_DIR = os.path.join(BASE_DIR, '..', 'vector_store', 'notices')
    notices_title_db = load_vector_db_manually(NOTICES_DB_DIR, "notices_title_index")
    print("âœ… Notices (ì œëª©) Vector DB ë¡œë”© ì„±ê³µ.")
except Exception as e:
    print(f"âŒ Notices (ì œëª©) Vector DB ë¡œë”© ì‹¤íŒ¨: {e}")

try:
    NOTICES_DB_DIR = os.path.join(BASE_DIR, '..', 'vector_store', 'notices')
    notices_content_db = load_vector_db_manually(NOTICES_DB_DIR, "notices_content_index")
    print("âœ… Notices (ë³¸ë¬¸) Vector DB ë¡œë”© ì„±ê³µ.")
except Exception as e:
    print(f"âŒ Notices (ë³¸ë¬¸) Vector DB ë¡œë”© ì‹¤íŒ¨: {e}")

try:
    JOBS_DB_DIR = os.path.join(BASE_DIR, '..', 'vector_store', 'jobs')
    jobs_db = load_vector_db_manually(JOBS_DB_DIR, "jobs_openai_index")
    print("âœ… Jobs Vector DB ë¡œë”© ì„±ê³µ.")
except Exception as e:
    print(f"âŒ Jobs Vector DB ë¡œë”© ì‹¤íŒ¨: {e}")


# --- 2. MongoDBì—ì„œ êµ¬ì„±ì› ì •ë³´ ê²€ìƒ‰ í•¨ìˆ˜ ---

def search_members_in_mongodb(query: str):
    match = re.search(r'([\wê°€-í£]{2,4})\s*(êµìˆ˜ë‹˜|êµìˆ˜|ì¡°êµ|ì„ ìƒë‹˜)', query)
    if not match:
        return None

    name_to_search = match.group(1)
    members = list(chatbot_db.members.find({"name": {"$regex": name_to_search}}))
    
    if members:
        context = "### ê²€ìƒ‰ëœ êµ¬ì„±ì› ì •ë³´:\n"
        for member in members:
            context += f"- ì´ë¦„: {member.get('name', 'ì •ë³´ ì—†ìŒ')}\n"
            context += f"  - ì§ìœ„: {member.get('position', 'ì •ë³´ ì—†ìŒ')}\n"
            context += f"  - ì—°êµ¬ì‹¤: {member.get('lab', 'ì •ë³´ ì—†ìŒ')}\n"
            context += f"  - ì´ë©”ì¼: {member.get('email', 'ì •ë³´ ì—†ìŒ')}\n"
            context += f"  - ì „í™”ë²ˆí˜¸: {member.get('phone', 'ì •ë³´ ì—†ìŒ')}\n---\n"
        return context
    return None

# --- 3. ë©”ì¸ ê²€ìƒ‰ í•¨ìˆ˜ (ë¼ìš°í„° ë¡œì§ í†µí•©) ---

def search_similar_documents(query: str, top_k: int = 2):
    print(f"--- [ì§„ë‹¨ 1/5] '{query}'ì— ëŒ€í•œ ë¬¸ì„œ ê²€ìƒ‰ ì‹œì‘ (top_k={top_k}) ---")
    member_keywords = ["êµìˆ˜", "êµìˆ˜ë‹˜", "ì—°êµ¬ì‹¤", "ì´ë©”ì¼", "ì—°ë½ì²˜", "ì¡°êµ", "ì„ ìƒë‹˜", "ì‚¬ë¬´ì‹¤", "ìœ„ì¹˜", "í˜¸ê´€", "í˜¸ì‹¤"]
    job_keywords = ["ì·¨ì—…", "ì¸í„´", "ì±„ìš©", "íšŒì‚¬", "ì§ë¬´", "ìì†Œì„œ", "ë©´ì ‘", "ê³µê³ "]

    if any(keyword in query for keyword in member_keywords):
        print(f"[ğŸ” DB ë¼ìš°íŒ…] '{query}' -> MongoDB êµ¬ì„±ì› ê²€ìƒ‰ ì‹œë„")
        # 2. MongoDB ê²€ìƒ‰ í•¨ìˆ˜ë¥¼ "í˜¸ì¶œ"í•©ë‹ˆë‹¤.
        mongo_context = search_members_in_mongodb(query)
        
        # 3. MongoDBì—ì„œ ê²°ê³¼ë¥¼ ì°¾ì•˜ë‹¤ë©´,
        if mongo_context:
            print(f"--- [ì§„ë‹¨ 5/5] MongoDBì—ì„œ ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ. ---")
            # 4. ì¦‰ì‹œ ê²°ê³¼ë¥¼ "ë°˜í™˜"í•˜ê³  í•¨ìˆ˜ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤. (Vector DBë¡œ ë„˜ì–´ê°€ì§€ ì•ŠìŒ)
            return mongo_context, ['name', 'position', 'lab', 'email', 'phone']
        
    selected_dbs = None
    if any(keyword in query for keyword in job_keywords):
        print("[ì§„ë‹¨] ì·¨ì—… DBë¥¼ ì„ íƒí•©ë‹ˆë‹¤.")
        selected_dbs = (jobs_db,)
    else:
        print("[ì§„ë‹¨] ê³µì§€ì‚¬í•­ DB (ì œëª©+ë³¸ë¬¸)ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.")
        selected_dbs = (notices_title_db, notices_content_db)
    
    if not any(db for db in selected_dbs if db is not None):
        return "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (DB ë¡œë”© ì‹¤íŒ¨).", []

    all_results = []
    for db in selected_dbs:
        if db:
            print(f"--- [ì§„ë‹¨ 2/5] DB ê°ì²´ì—ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹¤í–‰ ---")
            results = db.similarity_search_with_score(query, k=top_k)
            print(f"--- [ì§„ë‹¨ 3/5] ê²€ìƒ‰ ì™„ë£Œ. {len(results)}ê°œì˜ ê²°ê³¼ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤. ---")
            all_results.extend(results)

    unique_results = {}
    for doc, score in all_results:
        if doc.page_content not in unique_results or score < unique_results[doc.page_content][1]:
            unique_results[doc.page_content] = (doc, score)

    sorted_results = sorted(unique_results.values(), key=lambda item: item[1])
    print(f"--- [ì§„ë‹¨ 4/5] ì¤‘ë³µ ì œê±° í›„ {len(sorted_results)}ê°œì˜ ê²°ê³¼ë¥¼ ì–»ì—ˆìŠµë‹ˆë‹¤. ---")

    context = ""
    field_names = set()
    for doc, score in sorted_results[:top_k]:
        context += f"- ë‚´ìš©: {doc.page_content}\n"
        field_names.update(doc.metadata.keys())

    if not context:
        print("!!!!!!!!!!!!!! [ì§„ë‹¨ ê²°ê³¼] ìµœì¢… ì»¨í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ !!!!!!!!!!!!!!")
    else:
        print(f"--- [ì§„ë‹¨ 5/5] ìµœì¢… ì»¨í…ìŠ¤íŠ¸ ìƒì„± ì™„ë£Œ. ---")

    return context, list(field_names)



# app/search_engine.pyì˜ get_graduation_info í•¨ìˆ˜ ì „ì²´ë¥¼ ì´ê±¸ë¡œ êµì²´

import re # re ëª¨ë“ˆ import í™•ì¸ (ì—†ìœ¼ë©´ ì¶”ê°€)

def get_graduation_info(student_id_prefix: str, abeek_bool: bool):
    """
    MongoDBì—ì„œ í•™ë²ˆ(applied_year_range)ê³¼ ABEEK ìƒíƒœ(abeek: true/false)ì— ë§ëŠ” 
    ì¡¸ì—… ìš”ê±´ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤. (ì…ë ¥ í•™ë²ˆ '20' -> 2020 ë³€í™˜ ë¡œì§ ì¶”ê°€)
    """
    try:
        # 1. ì»¬ë ‰ì…˜ ì´ë¦„ í™•ì¸
        collection = chatbot_db["graduation_requirements"] 
        
        # --- [í•µì‹¬ ìˆ˜ì •: ì…ë ¥ í•™ë²ˆ -> 4ìë¦¬ ì—°ë„ ë³€í™˜] ---
        search_year = -1 # ê²€ìƒ‰ì— ì‚¬ìš©í•  4ìë¦¬ ì—°ë„
        
        try:
            # 2. ì‚¬ìš©ì ì…ë ¥ í•™ë²ˆ(student_id_prefix, ì˜ˆ: "18", "20")ì„ ìˆ«ìë¡œ ì‹œë„
            year_prefix_num = int(student_id_prefix)
            
            # 3. 2ìë¦¬ ìˆ«ìì´ë©´ ì•ì— "20"ì„ ë¶™ì—¬ 4ìë¦¬ ì—°ë„ë¡œ ë§Œë“¦
            if 0 <= year_prefix_num <= 99: # 00 ~ 99 ë²”ìœ„ì˜ 2ìë¦¬ ìˆ˜ (ë˜ëŠ” 1ìë¦¬)
                search_year = 2000 + year_prefix_num # ì˜ˆ: 20 -> 2020
                print(f"[í•™ë²ˆ ë³€í™˜] ì…ë ¥ '{student_id_prefix}' -> ê²€ìƒ‰ ì—°ë„ '{search_year}'")
            else:
                # 4ìë¦¬ ì´ìƒ ì…ë ¥ ì‹œ ê·¸ëŒ€ë¡œ ì‚¬ìš© (ì˜ˆì™¸ ì²˜ë¦¬)
                search_year = year_prefix_num
                print(f"[í•™ë²ˆ ë³€í™˜] ì…ë ¥ '{student_id_prefix}'ì€(ëŠ”) 4ìë¦¬ ì´ìƒì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ '{search_year}' ì‚¬ìš©")

        except ValueError:
            # í•™ë²ˆì´ ìˆ«ìê°€ ì•„ë‹ˆë©´ ê²€ìƒ‰ ë¶ˆê°€
            print(f"[ê²½ê³ ] ì…ë ¥ëœ í•™ë²ˆ '{student_id_prefix}'ì„(ë¥¼) ìˆ«ìë¡œ ë³€í™˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return f"ì…ë ¥í•˜ì‹  í•™ë²ˆ '{student_id_prefix}'ì´(ê°€) ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤."
        # --- [ìˆ˜ì • ì™„ë£Œ] ---

        # MongoDB ì¿¼ë¦¬ (abeek ì¡°ê±´ë§Œ ì‚¬ìš©)
        query = { "abeek": abeek_bool }
        all_reqs_for_abeek = list(collection.find(query))
        
        result = None 
        
        # í•™ë²ˆ ë²”ìœ„ ë§¤ì¹­ ë£¨í”„ (ì´ì „ê³¼ ë™ì¼)
        print("--- [get_graduation_info] í•™ë²ˆ ë²”ìœ„ ë§¤ì¹­ ì‹œì‘ ---")
        for i, req_doc in enumerate(all_reqs_for_abeek):
            range_str = req_doc.get("applied_year_range", "")
            print(f"  [ë£¨í”„ {i+1}] ë¬¸ì„œ ë²”ìœ„ í™•ì¸ ì¤‘: '{range_str}'")

            range_start_year = -1
            range_end_year = float('inf') 

            try:
                year_numbers = re.findall(r'\d+', range_str)

                if len(year_numbers) == 1: 
                    range_start_year = int(year_numbers[0])
                elif len(year_numbers) == 2: 
                    range_start_year = int(year_numbers[0])
                    range_end_year = int(year_numbers[1])

                print(f"    -> íŒŒì‹±ëœ ë²”ìœ„: Start={range_start_year}, End={range_end_year}, ê²€ìƒ‰ ì—°ë„={search_year}")

                # í•µì‹¬ ë¹„êµ ë¡œì§ (ì´ì œ search_yearëŠ” 4ìë¦¬)
                is_after_start = (range_start_year <= search_year)
                is_before_end = (search_year <= range_end_year)
                is_match = is_after_start and is_before_end

                print(f"    -> ë¹„êµ ê²°ê³¼: ({range_start_year} <= {search_year}) = {is_after_start}, ({search_year} <= {range_end_year}) = {is_before_end}, ìµœì¢… ë§¤ì¹­ = {is_match}")

                if is_match:
                    result = req_doc
                    print(f"    -> âœ… ë§¤ì¹­ ì„±ê³µ! ì´ ë¬¸ì„œ ì‚¬ìš©.")
                    break 
                else:
                    print(f"    -> âŒ ë§¤ì¹­ ì‹¤íŒ¨.")

            except Exception as parse_error:
                print(f"    -> âš ï¸ íŒŒì‹± ì˜¤ë¥˜ ë°œìƒ: {parse_error}")
                continue 
        
        # Context ìƒì„± ë° ë°˜í™˜ (ì´ì „ê³¼ ë™ì¼)
        if result:
            requirements = result.get('requirements', {}) 
            credits = requirements.get('credits', {}) 
            courses = requirements.get('required_courses', {}) 
            english = requirements.get('english', {}) 
            grad_qual = requirements.get('graduation_qualification', {}) 
            notes_list = requirements.get('notes', []) 
            notes_str = "\n".join([f"- {note}" for note in notes_list]) if notes_list else "ì—†ìŒ"

            context = f"""
            [ê²€ìƒ‰ëœ ë§ì¶¤í˜• ì¡¸ì—… ìš”ê±´ ({student_id_prefix}í•™ë²ˆ ê¸°ì¤€)] 
            - ì ìš© í•™ë²ˆ(DB): {result.get('applied_year_range', 'N/A')} ê¸°ì¤€
            - ABEEK ì´ìˆ˜ ì—¬ë¶€: {'O' if result.get('abeek') else 'X'}
            [í•™ì  ìš”ê±´]
            - ì´ ì´ìˆ˜ í•™ì : {credits.get('total', 'N/A')}í•™ì 
            - ì „ê³µ í•™ì : {credits.get('major', 'N/A')}í•™ì  
            - MSC í•™ì : {credits.get('msc', 'N/A')}í•™ì 
            - ê¸°ë³¸ì†Œì–‘ í•™ì : {credits.get('basic_literacy', 'N/A')}í•™ì 
            [í•„ìˆ˜ ê³¼ëª© ìš”ê±´] 
            - ì „ê³µ ê¸°ì´ˆ: {courses.get('major_basic', 'N/A')}
            - ì „ê³µ í•„ìˆ˜: {courses.get('major_required', 'N/A')}
            - MSC í•„ìˆ˜: {courses.get('msc_required', 'N/A')}
            - ê¸°ë³¸ì†Œì–‘ í•„ìˆ˜: {courses.get('basic_literacy_required', 'N/A')}
            [ì˜ì–´ ìš”ê±´] - {str(english)}
            [ì¡¸ì—… ìê²©] - {str(grad_qual)}
            [ë¹„ê³ ] {notes_str}
            """
            return context
        else:
            fail_msg = f"{student_id_prefix}í•™ë²ˆ, ABEEK {'O' if abeek_bool else 'X'} í•™ìƒì— ëŒ€í•œ ë§ì¶¤í˜• ì¡¸ì—… ìš”ê±´ì„ DBì—ì„œ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ì ìš© í•™ë²ˆ ë²”ìœ„ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”)"
            return fail_msg
            
    except Exception as e:
        print(f"MongoDB ì¡¸ì—… ìš”ê±´ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return "ì¡¸ì—… ìš”ê±´ DBë¥¼ ê²€ìƒ‰í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."