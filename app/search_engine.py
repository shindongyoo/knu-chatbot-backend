# app/search_engine.py
import os
import re
import faiss
import pickle
import traceback
from dotenv import load_dotenv
from langchain_community.vectorstores import FAISS as LangChainFAISS
from langchain_openai import OpenAIEmbeddings
from langchain_core.documents import Document
from langchain_community.docstore.in_memory import InMemoryDocstore
from app.database import chatbot_db
from langchain.tools import tool # <-- [ìƒˆë¡œ ì¶”ê°€] AI ë„êµ¬ import
from openai import OpenAI

load_dotenv()

embeddings = OpenAIEmbeddings(
    model="text-embedding-3-small",  # <-- "ada-002"ì—ì„œ ë³€ê²½!
    openai_api_key=os.getenv("OPENAI_API_KEY")
)

# app/search_engine.py ì˜ load_vector_db_manually í•¨ìˆ˜ë¥¼ ì´ê±¸ë¡œ êµì²´

def load_vector_db_manually(folder_path, index_name):
    faiss_path = os.path.join(folder_path, f"{index_name}.faiss")
    pkl_path = os.path.join(folder_path, f"{index_name}.pkl") # ì´ì œ ì´ê²Œ 'ì¢‹ì€ ì£¼ì†Œë¡'
    if not os.path.exists(faiss_path) or not os.path.exists(pkl_path):
        raise FileNotFoundError(f"'{folder_path}'ì—ì„œ DB íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {index_name}")
    
    index = faiss.read_index(faiss_path)
    with open(pkl_path, "rb") as f:
        # docs_dataëŠ” ì´ì œ [{'id':..., 'title':..., 'content':..., 'url':...}, ...] í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸
        docs_data = pickle.load(f) 
        
    documents = []
    docstore_dict = {}
    index_to_docstore_id = {}

    # â–¼â–¼â–¼ [í•µì‹¬ ìˆ˜ì •: Document ìƒì„± ë°©ì‹ ë³€ê²½] â–¼â–¼â–¼
    for i, doc_dict in enumerate(docs_data):
        # DB ìƒì„± ì‹œ ì‚¬ìš©ëœ 'full_text'ì™€ ìœ ì‚¬í•˜ê²Œ page_contentë¥¼ ì¬êµ¬ì„±
        # (DB ìƒì„± ì½”ë“œì˜ metadata í¬ë§·ì„ ì°¸ê³ í•˜ì—¬ í•„ë“œ ì¶”ê°€/ìˆ˜ì • í•„ìš”)
        metadata_str = (
            f"ğŸ“Œ ì œëª©: {doc_dict.get('title', '').strip()}\n"
            f"ğŸ“… ì‘ì„±ì¼: {doc_dict.get('date', '').strip()}\n"
            f"ğŸ¢ ê¸°ì—…ëª…: {doc_dict.get('company', 'N/A')}\n"
        )
        content_chunk = doc_dict.get('content', '').strip()
        detail_url = doc_dict.get('url', '') # 'url' í‚¤ ì‚¬ìš© (DB ìƒì„± ì½”ë“œ ì°¸ê³ )

        # DB ìƒì„± ì½”ë“œì˜ full_text í¬ë§·ê³¼ ìµœëŒ€í•œ ìœ ì‚¬í•˜ê²Œ ë§Œë“¦
        reconstructed_page_content = f"{metadata_str}\n{content_chunk}\n\nğŸ”— ìì„¸í•œ ë‚´ìš©ì€ ë§í¬ë¥¼ ì°¸ê³ í•˜ì„¸ìš”: {detail_url}"
        
        # ë©”íƒ€ë°ì´í„°ì—ëŠ” ì›ë³¸ ë”•ì…”ë„ˆë¦¬ ì „ì²´ë¥¼ ë„£ì–´ë„ ë˜ê³ , í•„ìš”í•œ ê²ƒë§Œ ë„£ì–´ë„ ë¨
        metadata = doc_dict.copy() # ì›ë³¸ ë³µì‚¬í•´ì„œ ì‚¬ìš©

        # LangChain Document ê°ì²´ ìƒì„± (page_contentì— ì¬êµ¬ì„±ëœ í…ìŠ¤íŠ¸ ì‚¬ìš©)
        doc_obj = Document(page_content=reconstructed_page_content, metadata=metadata)
        documents.append(doc_obj)
        
        # Docstore ë° ë§¤í•‘ ìƒì„± (ê¸°ì¡´ ë¡œì§)
        doc_id = str(i)
        docstore_dict[doc_id] = doc_obj
        index_to_docstore_id[i] = doc_id
    # â–²â–²â–² [ìˆ˜ì • ì™„ë£Œ] â–²â–²â–²

    docstore = InMemoryDocstore(docstore_dict)

    # LangChainFAISS ê°ì²´ ìƒì„± (embedding_function ì‚¬ìš©)
    return LangChainFAISS(
        embedding_function=embeddings, 
        index=index, 
        docstore=docstore, 
        index_to_docstore_id=index_to_docstore_id
    )

def optimize_search_query(query: str) -> str:
    """
    ì‚¬ìš©ìì˜ ì• ë§¤í•œ ì§ˆë¬¸ì„ ê³µì§€ì‚¬í•­/ê·œì • DB ê²€ìƒ‰ì— ì í•©í•œ 'í•µì‹¬ í‚¤ì›Œë“œ ë¬¸ì¥'ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    ë‹¨, ê¸°ì—…ëª…ì´ë‚˜ êµìˆ˜ëª… ê°™ì€ ê³ ìœ ëª…ì‚¬ëŠ” ì ˆëŒ€ ë³€ê²½í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
    ì˜ˆ: "í•™êµ ì¢€ ì‰¬ê³  ì‹¶ì–´" -> "íœ´í•™ ì‹ ì²­ ì ˆì°¨ ë° ê¸°ê°„"
    ì˜ˆ: "ëˆ ì£¼ëŠ”ê±° ë­ ìˆì–´?" -> "ì¥í•™ê¸ˆ ì¢…ë¥˜ ë° ì‹ ì²­ ì•ˆë‚´"
    """
    try:
        client = OpenAI() # í™˜ê²½ë³€ìˆ˜ API KEY ì‚¬ìš©
        
        system_prompt = """ë‹¹ì‹ ì€ ê²€ìƒ‰ì–´ ìµœì í™” ë„êµ¬ì…ë‹ˆë‹¤. 
        ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ëŒ€í•™êµ ê³µì§€ì‚¬í•­ì´ë‚˜ ê·œì •ì§‘ì—ì„œ ê²€ìƒ‰í•˜ê¸° ì¢‹ì€ 'ê³µì‹ ìš©ì–´'ë¡œ ë³€í™˜í•˜ì„¸ìš”.

        [ì ˆëŒ€ ê·œì¹™]
        1. **ê¸°ì—…ëª…(ì‚¼ì„±, í˜„ëŒ€, LG ë“±)ì´ë‚˜ êµìˆ˜ë‹˜ ì„±í•¨(í•œì„¸ê²½ ë“±) ê°™ì€ ê³ ìœ ëª…ì‚¬ëŠ” ì ˆëŒ€ë¡œ ë³€ê²½í•˜ê±°ë‚˜ ì‚­ì œí•˜ì§€ ë§ˆì„¸ìš”.** ê·¸ëŒ€ë¡œ í¬í•¨ì‹œì¼œì•¼ í•©ë‹ˆë‹¤.
        2. "ì‚¼ì„± ì±„ìš©" -> "ì‚¼ì„± ì±„ìš© ê³µê³  ëª¨ì§‘ ìš”ê°•" (O)
        3. "ì‚¼ì„± ì±„ìš©" -> "ëŒ€í•™êµ ì·¨ì—… ì•ˆë‚´" (X - ê¸°ì—…ëª…ì´ ì‚¬ë¼ì§!)
        4. "ì‰¬ê³  ì‹¶ì–´" -> "íœ´í•™ ì‹ ì²­ ì ˆì°¨" (O - ì• ë§¤í•œ í‘œí˜„ì€ ë³€í™˜)
        """
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"ì§ˆë¬¸: {query}"}
            ],
            temperature=0
        )
        optimized_query = response.choices[0].message.content.strip()
        print(f"    [ê²€ìƒ‰ì–´ ë³€í™˜] '{query}' -> '{optimized_query}'")
        return optimized_query
    except Exception as e:
        print(f"    [ë³€í™˜ ì‹¤íŒ¨] ì›ë³¸ ì‚¬ìš©: {e}")
        return query

# Vector DB ë¡œë”©
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
notices_title_db = None
notices_content_db = None
jobs_db = None

try:
    NOTICES_DB_DIR = os.path.join(BASE_DIR, '..', 'vector_store', 'notices')
    notices_title_db = load_vector_db_manually(NOTICES_DB_DIR, "notices_title_index")
    print("âœ… Notices (ì œëª©) Vector DB ë¡œë”© ì„±ê³µ.")
except Exception as e:
    print(f"âŒ Notices (ì œëª©) Vector DB ë¡œë”© ì‹¤íŒ¨: {e}")

try:
    NOTICES_DB_DIR = os.path.join(BASE_DIR, '..', 'vector_store', 'notices')
    notices_content_db = load_vector_db_manually(NOTICES_DB_DIR, "notices_content_index")
    print("âœ… Notices (ë³¸ë¬¸) Vector DB ë¡œë”© ì„±ê³µ.")
except Exception as e:
    print(f"âŒ Notices (ë³¸ë¬¸) Vector DB ë¡œë”© ì‹¤íŒ¨: {e}")

try:
    JOBS_DB_DIR = os.path.join(BASE_DIR, '..', 'vector_store', 'jobs')
    jobs_db = load_vector_db_manually(JOBS_DB_DIR, "jobs_openai_index")
    print("âœ… Jobs Vector DB ë¡œë”© ì„±ê³µ.")
except Exception as e:
    print(f"âŒ Jobs Vector DB ë¡œë”© ì‹¤íŒ¨: {e}")


# --- 2. MongoDBì—ì„œ êµ¬ì„±ì› ì •ë³´ ê²€ìƒ‰ í•¨ìˆ˜ ---

def search_members_in_mongodb(query: str):
    match = re.search(r'([\wê°€-í£]{2,4})\s*(êµìˆ˜ë‹˜|êµìˆ˜|ì¡°êµ|ì„ ìƒë‹˜)', query)
    if not match:
        return None

    name_to_search = match.group(1)
    members = list(chatbot_db.members.find({"name": {"$regex": name_to_search}}))
    
    if members:
        context = "### ê²€ìƒ‰ëœ êµ¬ì„±ì› ì •ë³´:\n"
        for member in members:
            context += f"- ì´ë¦„: {member.get('name', 'ì •ë³´ ì—†ìŒ')}\n"
            context += f"  - ì§ìœ„: {member.get('position', 'ì •ë³´ ì—†ìŒ')}\n"
            context += f"  - ì—°êµ¬ì‹¤: {member.get('lab', 'ì •ë³´ ì—†ìŒ')}\n"
            context += f"  - ì „ê³µë¶„ì•¼: {member.get('major', 'ì •ë³´ ì—†ìŒ')}\n"
            context += f"  - ì´ë©”ì¼: {member.get('email', 'ì •ë³´ ì—†ìŒ')}\n"
            context += f"  - ì „í™”ë²ˆí˜¸: {member.get('phone', 'ì •ë³´ ì—†ìŒ')}\n---\n"
        return context
    return None

# --- 3. ë©”ì¸ ê²€ìƒ‰ í•¨ìˆ˜ (ë¼ìš°í„° ë¡œì§ í†µí•©) ---
@tool
def search_similar_documents(query: str, top_k: int = 3) -> str:
    """
    "ìˆ˜ê°•ì‹ ì²­", "ì¥í•™ìƒ", "êµìˆ˜ë‹˜ ì •ë³´", "í•™ì‚¬ ì¼ì •" ë“± 
    'ì¡¸ì—… ìš”ê±´'ì´ë‚˜ 'êµê³¼ê³¼ì •'ì„ ì œì™¸í•œ ëª¨ë“  ì¼ë°˜ì ì¸ êµë‚´ ì •ë³´ë¥¼ ê²€ìƒ‰í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    ì§ˆë¬¸ì´ ì• ë§¤í•´ë„ ì°°ë–¡ê°™ì´ ì•Œì•„ë“£ê³  ê²€ìƒ‰í•©ë‹ˆë‹¤.
    """
    print(f"\n--- [ì—ì´ì „íŠ¸ ë„êµ¬ 1: ì¼ë°˜ ê²€ìƒ‰] ì›ë³¸ ì§ˆë¬¸: '{query}' ---")
    
    # 1. ì§ˆë¬¸ì„ DB ì¹œí™”ì ìœ¼ë¡œ ë³€í™˜ (ì—¬ê¸°ê°€ í•µì‹¬!)
    optimized_query = optimize_search_query(query)
    
    # 2. êµìˆ˜ë‹˜ í‚¤ì›Œë“œ í™•ì¸ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    member_keywords = ["êµìˆ˜", "êµìˆ˜ë‹˜", "ì—°êµ¬ì‹¤", "ì´ë©”ì¼", "ì—°ë½ì²˜", "ì¡°êµ", "ì„ ìƒë‹˜"]
    job_keywords = ["ì·¨ì—…", "ì¸í„´", "ì±„ìš©", "íšŒì‚¬", "ì§ë¬´"]

    # (MongoDB ë¼ìš°íŒ… ë¡œì§)
    if any(keyword in query for keyword in member_keywords):
        print(f"    [ë¼ìš°íŒ…] êµìˆ˜ë‹˜ ê²€ìƒ‰ ëª¨ë“œ")
        mongo_context = search_members_in_mongodb(query) # ì›ë³¸ ì´ë¦„ ì‚¬ìš© (ì´ë¦„ì€ ë³€í™˜í•˜ë©´ ì•ˆë¨)
        if mongo_context:
            return mongo_context
        else:
            print(f"    [ë¼ìš°íŒ…] MongoDB ê²°ê³¼ ì—†ìŒ. Vector DBë¡œ ê³„ì† ì§„í–‰...")
    
    # 3. Vector DB ê²€ìƒ‰ (ë³€í™˜ëœ optimized_query ì‚¬ìš©!)
    selected_dbs = None
    if any(keyword in query for keyword in job_keywords):
        selected_dbs = (jobs_db,)
    else:
        selected_dbs = (notices_title_db, notices_content_db)
    
    if not any(db for db in selected_dbs if db is not None):
        return "ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (DB ë¡œë”© ì‹¤íŒ¨)."

    all_results_with_scores = []
    
    print(f"    [Vector DB ê²€ìƒ‰] í‚¤ì›Œë“œ: '{optimized_query}'")
    for db in selected_dbs:
        if db:
            # ì—¬ê¸°ì„œ ë³€í™˜ëœ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰í•©ë‹ˆë‹¤!
            results = db.similarity_search_with_score(optimized_query, k=top_k)
            all_results_with_scores.extend(results)

    # (ì¤‘ë³µ ì œê±° ë° ì •ë ¬ ë¡œì§ - ê¸°ì¡´ê³¼ ë™ì¼)
    unique_results = {}
    for doc, score in all_results_with_scores:
        if doc.page_content not in unique_results or score < unique_results[doc.page_content][1]:
            unique_results[doc.page_content] = (doc, score)
    sorted_results = sorted(unique_results.values(), key=lambda item: item[1])

    # (Context ìƒì„± - ê¸°ì¡´ê³¼ ë™ì¼)
    context = ""
    for doc, score in sorted_results[:top_k]:
        # ë„ˆë¬´ ê´€ë ¨ ì—†ëŠ” ê²ƒ(ì ìˆ˜ 1.6 ì´ìƒ)ì€ í•„í„°ë§ (ì„ íƒ ì‚¬í•­)
        if score < 1.6: 
            context += f"- ë‚´ìš© (ì ìˆ˜: {score:.4f}): {doc.page_content}\n---\n"

    if not context:
        return f"'{query}'(ë³€í™˜: {optimized_query})ì— ëŒ€í•œ ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
    else:
        return context

@tool
def get_graduation_info(student_id_prefix: str, abeek_bool: bool) -> str:
    """
    [ì§„ë‹¨ ëª¨ë“œ] ì¡¸ì—… ìš”ê±´ ê²€ìƒ‰ í•¨ìˆ˜
    """
    print(f"\n--- [ì§„ë‹¨ ì‹œì‘] í•™ë²ˆ: {student_id_prefix}, ABEEK: {abeek_bool} ---")
    
    try:
        # 1. ì»¬ë ‰ì…˜ ì´ë¦„ í™•ì¸ (ê°€ì¥ í”í•œ ì›ì¸!)
        COLLECTION_NAME = "graduation_requirements2" # <--- ë‹˜ DB ì»¬ë ‰ì…˜ ì´ë¦„ê³¼ ê°™ì€ì§€ ê¼­ í™•ì¸!
        collection = chatbot_db[COLLECTION_NAME] 
        
        # 2. í•™ë²ˆ ë³€í™˜
        search_year = -1 
        try:
            year_prefix_num = int(student_id_prefix)
            if 0 <= year_prefix_num <= 99: 
                search_year = 2000 + year_prefix_num 
            else:
                search_year = year_prefix_num
            print(f"[1. í•™ë²ˆ ë³€í™˜] ì…ë ¥ '{student_id_prefix}' -> ê²€ìƒ‰ìš© ì—°ë„ '{search_year}'")
        except ValueError:
            return f"ì…ë ¥í•˜ì‹  í•™ë²ˆ '{student_id_prefix}'ì´(ê°€) ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤."
        
        # 3. DB ì¿¼ë¦¬ ì‹¤í–‰
        query = { "abeek": abeek_bool }
        print(f"[2. DB ì¿¼ë¦¬] ì¡°ê±´: {query}")
        
        all_reqs_for_abeek = list(collection.find(query))
        print(f"[3. ì¿¼ë¦¬ ê²°ê³¼] ì´ {len(all_reqs_for_abeek)}ê°œì˜ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        
        if len(all_reqs_for_abeek) == 0:
            print("âš ï¸ [ê²½ê³ ] í•´ë‹¹ ì¡°ê±´ì˜ ë¬¸ì„œê°€ 0ê°œì…ë‹ˆë‹¤. ì»¬ë ‰ì…˜ ì´ë¦„ì´ë‚˜ ë°ì´í„°(abeek í•„ë“œ)ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            return f"DBì—ì„œ ABEEK ìƒíƒœê°€ {abeek_bool}ì¸ ë¬¸ì„œë¥¼ í•˜ë‚˜ë„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."

        result = None 
        
        # 4. ë§¤ì¹­ ë£¨í”„
        print("[4. ë²”ìœ„ ë§¤ì¹­ ì‹œì‘]")
        for i, req_doc in enumerate(all_reqs_for_abeek):
            range_str = req_doc.get("applied_year_range", "í•„ë“œì—†ìŒ")
            print(f"  [{i+1}ë²ˆ ë¬¸ì„œ] ë²”ìœ„: '{range_str}'")
            
            try:
                year_numbers = re.findall(r'\d+', str(range_str))
                if not year_numbers:
                    print("    -> âš ï¸ ìˆ«ì ì¶”ì¶œ ì‹¤íŒ¨")
                    continue

                range_start = int(year_numbers[0])
                # ìˆ«ìê°€ 1ê°œë©´(ì˜ˆ: 2025~) ëì€ ë¬´í•œëŒ€, 2ê°œë©´(ì˜ˆ: 2018~2022) ë‘ë²ˆì§¸ ìˆ«ì
                range_end = int(year_numbers[1]) if len(year_numbers) > 1 else float('inf')
                
                # ë¹„êµ ë¡œì§
                is_match = (range_start <= search_year <= range_end)
                
                print(f"    -> íŒŒì‹±: {range_start} ~ {range_end}")
                print(f"    -> ë¹„êµ: {range_start} <= {search_year} <= {range_end} ? ê²°ê³¼: {is_match}")

                if is_match:
                    result = req_doc
                    print("    -> ğŸ‰ ì •ë‹µ ë¬¸ì„œë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                    break 
            except Exception as e:
                print(f"    -> âŒ ì—ëŸ¬ ë°œìƒ: {e}")
                continue
            
        # --- [3. Context ìƒì„± (ìµœì¢… ìƒì„¸ ìŠ¤í‚¤ë§ˆ ë°˜ì˜)] ---
        if result:
            # â–¼â–¼â–¼ [í•µì‹¬ ìˆ˜ì •: ìƒì„¸ ìŠ¤í‚¤ë§ˆ ë°˜ì˜] â–¼â–¼â–¼
            
            # ì•ˆì „í•˜ê²Œ ë°ì´í„° ì¶”ì¶œ (ê°ì²´ê°€ ì—†ìœ¼ë©´ ë¹ˆ dict ë°˜í™˜)
            requirements = result.get('requirements', {}) 
            credits = requirements.get('credits', {})
            credit_basic = credits.get('ê¸°ë³¸ì†Œì–‘', {}) 
            credit_msc = credits.get('ì „ê³µê¸°ë°˜', "N/A") # ì „ê³µê¸°ë°˜ì€ ê°ì²´ê°€ ì•„ë‹Œ ì§ì ‘ ê°’
            credit_major = credits.get('ê³µí•™ì „ê³µ', {})
            
            courses = requirements.get('required_courses', {}) 
            courses_basic = courses.get('ê¸°ë³¸ì†Œì–‘', [])
            courses_msc = courses.get('ì „ê³µê¸°ë°˜', [])
            courses_major = courses.get('ê³µí•™ì „ê³µ', [])

            english = requirements.get('english', {})
            eng_tests = english.get('tests', [])
            eng_sub = english.get('substitution', [])
            eng_notes = english.get('notes', [])

            grad_qual = requirements.get('graduation_qualification', {})
            advisor = grad_qual.get('advisor_consultation', {})
            software = grad_qual.get('software_credits', {})
            sw_courses = software.get('required_courses', [])
            sw_sub = software.get('substitution', [])
            grad_qual_notes = grad_qual.get('notes', [])

            # ë¦¬ìŠ¤íŠ¸(Array) ì •ë³´ë¥¼ ì½¤ë§ˆ(,)ë¡œ êµ¬ë¶„ëœ ë¬¸ìì—´ë¡œ ë³€í™˜
            def format_list(items):
                return ", ".join(items) if items else "í•´ë‹¹ ì—†ìŒ"
            
            # ì˜ì–´ ì‹œí—˜ ìš”ê±´ í¬ë§·íŒ…
            def format_eng_tests(tests):
                if not tests: return "í•´ë‹¹ ì—†ìŒ"
                return ", ".join([f"{test.get('name')}: {test.get('score')}ì  ì´ìƒ" for test in tests])

            context = f"""
            [ê²€ìƒ‰ëœ ë§ì¶¤í˜• ì¡¸ì—… ìš”ê±´ ({student_id_prefix}í•™ë²ˆ, ABEEK {'O' if abeek_bool else 'X'})] 
            - ì ìš© í•™ë²ˆ(DB): {result.get('applied_year_range', 'N/A')} ê¸°ì¤€

            [1. í•™ì  ìš”ê±´ (Credits)]
            - ì´ ì´ìˆ˜ í•™ì : {credits.get('total', 'N/A')}í•™ì 
            - ê¸°ë³¸ì†Œì–‘(êµì–‘): {credit_basic.get('min', 'N/A')}í•™ì  ì´ìƒ
            - ì „ê³µê¸°ë°˜(MSC): {credit_msc}í•™ì 
            - ê³µí•™ì „ê³µ(ì „ê³µ): {credit_major.get('total', 'N/A')}í•™ì  (ì´ ì¤‘ ì„¤ê³„ {credit_major.get('design', 'N/A')}í•™ì  í¬í•¨)
            - ì „ê³µ ì°¸ê³ : {credit_major.get('note', 'N/A')}

            [2. í•„ìˆ˜ ê³¼ëª© ìš”ê±´ (Required Courses)] 
            - ê¸°ë³¸ì†Œì–‘ í•„ìˆ˜: {format_list(courses_basic)}
            - ì „ê³µê¸°ë°˜ í•„ìˆ˜: {format_list(courses_msc)}
            - ê³µí•™ì „ê³µ í•„ìˆ˜: {format_list(courses_major)}

            [3. ì˜ì–´ ìš”ê±´ (English)]
            - ê³µì¸ ì‹œí—˜ ê¸°ì¤€: {format_eng_tests(eng_tests)}
            - ë©´ì œ ê¸°ì¤€: {format_list(eng_sub)}
            - ë¹„ê³ : {format_list(eng_notes)}

            [4. ì¡¸ì—… ìê²© (Graduation Qualification)]
            - ì§€ë„êµìˆ˜ ìƒë‹´: {advisor.get('count', 'N/A')}íšŒ ì´ìƒ ({advisor.get('note', 'N/A')})
            - ì†Œí”„íŠ¸ì›¨ì–´ ì´ìˆ˜: {software.get('min', 'N/A')}í•™ì  ì´ìƒ ({software.get('note', 'N/A')})
            - (SW ì¸ì • ê³¼ëª©: {format_list(sw_courses)})
            - (SW ë©´ì œ ê¸°ì¤€: {format_list(sw_sub)})
            - ì¡¸ì—… ìê²© ë¹„ê³ : {format_list(grad_qual_notes)}

            [ì¢…í•© ë¹„ê³ ]
            {format_list(requirements.get('notes', []))}
            """
            # â–²â–²â–² [ìˆ˜ì • ì™„ë£Œ] â–²â–²â–²
            return context
        else:
            print("[5. ê²°ê³¼] ë§¤ì¹­ë˜ëŠ” ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return f"{student_id_prefix}í•™ë²ˆ({search_year}), ABEEK {abeek_bool} ì¡°ê±´ì— ë§ëŠ” ë²”ìœ„ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
    except Exception as e:
        print(f"!!!!!!!!!!!!!! ì¹˜ëª…ì  ì˜¤ë¥˜ !!!!!!!!!!!!!!")
        traceback.print_exc()
        return "ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."


@tool
def search_curriculum_subjects(student_id_prefix: str = None, abeek_bool: bool = None, grade: int = None, semester: int = None, subject_type: str = None, module: str = None) -> str:
    """
    [ì„¤ëª…ì„œ] 'êµê³¼ê³¼ì •', 'ê°œì„¤ ê³¼ëª©', 'ìˆ˜ì—… ëª©ë¡'ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    [ì¤‘ìš”] ì‚¬ìš©ìê°€ 'ëª¨ë“ˆ'(ì˜ˆ: ìŠ¤ë§ˆíŠ¸ê³„í†µ, ì „ë ¥ì „ì)ì„ ë¬¼ì–´ë³´ë©´ ë‹¤ë¥¸ ì¸ì ì—†ì´ moduleë§Œ ì…ë ¥í•´ë„ ë©ë‹ˆë‹¤.
    """
    print(f"\n--- [ë„êµ¬ ì‹¤í–‰] êµê³¼ê³¼ì • ê²€ìƒ‰ (ëª¨ë“ˆ: {module}) ---")
    
    try:
        collection = chatbot_db["graduation_requirements2"] 
        
        target_docs = []

        # 1. ë¬¸ì„œ í™•ë³´ ì „ëµ
        if module:
            print("    -> ëª¨ë“ˆ ê²€ìƒ‰ ëª¨ë“œ: ì „ì²´ ë¬¸ì„œ ìŠ¤ìº”")
            # ëª¨ë“ˆ ê²€ìƒ‰ì€ í•™ë²ˆ/ABEEK ë¬´ì‹œí•˜ê³  ì „ì²´ ë¬¸ì„œ ìŠ¤ìº”
            target_docs = list(collection.find({}))
        
        elif student_id_prefix:
            # í•™ë²ˆ ê²€ìƒ‰ ëª¨ë“œ
            search_year = 2000 + int(student_id_prefix) if int(student_id_prefix) < 100 else int(student_id_prefix)
            query = {"abeek": abeek_bool} if abeek_bool is not None else {}
            all_docs = list(collection.find(query))
            
            for doc in all_docs:
                range_str = doc.get("applied_year_range", "")
                try:
                    nums = re.findall(r'\d+', range_str)
                    if not nums: continue
                    start = int(nums[0])
                    end = int(nums[1]) if len(nums) > 1 else float('inf')
                    if start <= search_year <= end:
                        target_docs.append(doc)
                        break 
                except: continue

        if not target_docs:
            # ì•ˆì „ì¥ì¹˜: í˜¹ì‹œ ëª¨ë¥´ë‹ˆ ê·¸ëƒ¥ ë‹¤ ê°€ì ¸ì™€ë´„ (ë°ì´í„°ê°€ ì ìœ¼ë¯€ë¡œ ê°€ëŠ¥)
            target_docs = list(collection.find({}))

        # 2. ê³¼ëª© í•„í„°ë§
        results = []
        search_module = module.replace(" ", "") if module else ""

        print(f"--- [ë””ë²„ê¹…] ë¬¸ì„œ {len(target_docs)}ê°œ ë‚´ë¶€ íƒìƒ‰ ì‹œì‘ ---")

        for doc in target_docs:
            # â–¼â–¼â–¼ [í•µì‹¬ ìˆ˜ì •] ë°ì´í„° ìœ„ì¹˜ ìë™ íƒìƒ‰ â–¼â–¼â–¼
            # 1ìˆœìœ„: ìµœìƒìœ„ì— curriculumì´ ìˆëŠ” ê²½ìš°
            curriculum = doc.get('curriculum', {})
            subjects = curriculum.get('subjects', [])
            
            # 2ìˆœìœ„: requirements ì•ˆì— curriculumì´ ìˆëŠ” ê²½ìš° (ì§€ê¸ˆ ë‹˜ì˜ DB ìƒí™©!)
            if not subjects:
                requirements = doc.get('requirements', {})
                curriculum = requirements.get('curriculum', {})
                subjects = curriculum.get('subjects', [])
            # â–²â–²â–² [ìˆ˜ì • ì™„ë£Œ] â–²â–²â–²
            
            for sub in subjects:
                # ëª¨ë“ˆ ì²´í¬
                if module:
                    sub_module = sub.get('module', '').replace(" ", "")
                    if search_module not in sub_module:
                        continue 

                # ë‚˜ë¨¸ì§€ í•„í„°
                if grade and sub.get('grade') != grade: continue
                if semester and sub.get('semester') != semester: continue
                
                # ê²°ê³¼ í¬ë§·íŒ…
                mod_info = f" [ëª¨ë“ˆ: {sub.get('module')}]" if sub.get('module') else ""
                info = f"- {sub.get('course_name')} (í•™ë…„: {sub.get('grade')}, êµ¬ë¶„: {sub.get('type')}){mod_info}"
                
                if info not in results:
                    results.append(info)

        if not results:
            return f"ì¡°ê±´(ëª¨ë“ˆ: {module})ì— ë§ëŠ” ê³¼ëª©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. DB êµ¬ì¡°ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

        return f"[ê²€ìƒ‰ ê²°ê³¼] ì´ {len(results)}ê°œ ê³¼ëª© ë°œê²¬:\n" + "\n".join(results[:30])

    except Exception as e:
        traceback.print_exc()
        return "ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ"
    
@tool
def search_professors_by_keyword(keyword: str) -> str:
    """
    "ìŠ¤ë§ˆíŠ¸ ê³„í†µ", "ì „ë ¥ì „ì", "ë°˜ë„ì²´", "ì¸ê³µì§€ëŠ¥" ë“± íŠ¹ì • 'ë¶„ì•¼'ë‚˜ 'ëª¨ë“ˆ' í‚¤ì›Œë“œë¡œ 
    ê´€ë ¨ëœ êµìˆ˜ë‹˜ ì •ë³´ë¥¼ ì°¾ì„ ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤. (ì´ë¦„ ê²€ìƒ‰ ì•„ë‹˜)
    """
    print(f"\n--- [ì—ì´ì „íŠ¸ ë„êµ¬ 4: êµìˆ˜ë‹˜ ë¶„ì•¼ ê²€ìƒ‰] í‚¤ì›Œë“œ: {keyword} ---")
    try:
        collection = chatbot_db["members"] 
        
        # ì •ê·œì‹ìœ¼ë¡œ 'ì „ê³µ(major)' ë˜ëŠ” 'ì—°êµ¬ì‹¤(lab)'ì— í‚¤ì›Œë“œê°€ í¬í•¨ëœ êµìˆ˜ ê²€ìƒ‰
        query = {
            "$or": [
                {"name": {"$regex": keyword, "$options": "i"}},     # ì´ë¦„ìœ¼ë¡œ ì°¾ê¸° (í•„ìˆ˜!)
                {"major": {"$regex": keyword, "$options": "i"}},    # ì „ê³µìœ¼ë¡œ ì°¾ê¸°
                {"lab": {"$regex": keyword, "$options": "i"}},      # ì—°êµ¬ì‹¤ë¡œ ì°¾ê¸°
                {"position": {"$regex": keyword, "$options": "i"}}, # ì§ìœ„ë¡œ ì°¾ê¸°
                {"email": {"$regex": keyword, "$options": "i"}}     # ì´ë©”ì¼ë¡œ ì°¾ê¸°
            ]
        }
        
        results = list(collection.find(query))
        
        if not results:
            return f"'{keyword}' ë¶„ì•¼ì™€ ê´€ë ¨ëœ êµìˆ˜ë‹˜ ì •ë³´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
        
        context = f"[ê²€ìƒ‰ëœ '{keyword}' ê´€ë ¨ êµìˆ˜ë‹˜ ëª©ë¡ (ì´ {len(results)}ëª…)]\n"
            
        # ê²°ê³¼ í¬ë§·íŒ…
        for member in results:
            context += f"- ì´ë¦„: {member.get('name', 'ì •ë³´ì—†ìŒ')}\n"
            context += f"  - ì§ìœ„: {member.get('position', 'ì •ë³´ì—†ìŒ')}\n"
            context += f"  - ì—°êµ¬ì‹¤: {member.get('lab', 'ì •ë³´ì—†ìŒ')}\n"
            context += f"  - ì „ê³µë¶„ì•¼: {member.get('major', 'ì •ë³´ì—†ìŒ')}\n"
            context += f"  - ì´ë©”ì¼: {member.get('email', 'ì •ë³´ì—†ìŒ')}\n"
            context += f"  - ì „í™”ë²ˆí˜¸: {member.get('phone', 'ì •ë³´ì—†ìŒ')}\n"
            context += "---\n"
            
        return context

    except Exception as e:
        print(f"êµìˆ˜ë‹˜ ë¶„ì•¼ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        traceback.print_exc()
        return "êµìˆ˜ë‹˜ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

@tool
def get_employment_stats(year: int = 2023) -> str:
    """
    [ì„¤ëª…ì„œ] 'ì·¨ì—…ë¥ ', 'ì·¨ì—… í†µê³„', 'ì§„ë¡œ í˜„í™©', 'ì–´ë–¤ íšŒì‚¬ ê°”ì–´?', 'ëŒ€ê¸°ì—… ì·¨ì—… ë¹„ìœ¨' ë“±
    í•™ê³¼ ì¡¸ì—…ìƒë“¤ì˜ ì·¨ì—… ì‹¤ì ê³¼ í†µê³„ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
    ê¸°ë³¸ì ìœ¼ë¡œ 2023ë…„ ë°ì´í„°ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    """
    print(f"\n--- [ì—ì´ì „íŠ¸ ë„êµ¬ 4: ì·¨ì—… í†µê³„ ê²€ìƒ‰] ì—°ë„: {year} ---")
    
    try:
        # 1. ì»¬ë ‰ì…˜ ì´ë¦„ í™•ì¸ (MongoDBì— ì´ ì»¬ë ‰ì…˜ì´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤!)
        collection = chatbot_db["employment_rate_2023"] 
        
        # 2. ì—°ë„(year)ë¡œ ë¬¸ì„œ ê²€ìƒ‰
        query = {"year": year}
        result = collection.find_one(query)
        
        if not result:
            # íŠ¹ì • ì—°ë„ê°€ ì—†ìœ¼ë©´ ê°€ì¥ ìµœì‹  ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ë„ë¡ ìœ ë„í•˜ê±°ë‚˜ ì „ì²´ ëª©ë¡ í™•ì¸
            return f"{year}ë…„ë„ ì·¨ì—… í†µê³„ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            
        # 3. ë°ì´í„° íŒŒì‹± ë° Context ìƒì„±
        stats = result.get('stats', {})
        
        # 3-1. ì „ì²´ í˜„í™©
        overall = stats.get('1_overall_status', {})
        overall_text = (
            f"- ì¡¸ì—…ì: {overall.get('graduates')}ëª…, ì·¨ì—…ì: {overall.get('employed')}ëª…\n"
            f"- ì§„í•™: {overall.get('advanced_study')}ëª…, ë¯¸ì·¨ì—…: {overall.get('unemployed')}ëª…\n"
            f"- ğŸ“ˆ ì·¨ì—…ë¥ : {overall.get('employment_rate')} (ì§„í•™ë¥ : {overall.get('advancement_rate')})"
        )
        
        # 3-2. ê¸°ì—… í˜•íƒœë³„ ìš”ì•½
        company_summary = stats.get('3_company_type_summary', {})
        dist_list = company_summary.get('distribution', [])
        dist_text = ", ".join([f"{d['type']}: {d['ratio']}({d['count']}ëª…)" for d in dist_list])
        
        # 3-3. ìƒì„¸ ì·¨ì—…ì²˜ (ë¦¬ìŠ¤íŠ¸ í¬ë§·íŒ… í—¬í¼ í•¨ìˆ˜)
        def format_companies(company_list):
            if not company_list: return "ì—†ìŒ"
            # ì˜ˆ: "í˜„ëŒ€ìë™ì°¨(5), LGì „ì(3)"
            return ", ".join([f"{c['name']}({c['count']}ëª…)" for c in company_list])

        details = stats.get('4_employment_details', {})
        large_ent = format_companies(details.get('large_enterprise', []))
        medium_ent = format_companies(details.get('medium_enterprise', []))
        small_ent = format_companies(details.get('small_medium_enterprise', []))
        public_inst = format_companies(details.get('public_institution', []))
        
        # 4. ìµœì¢… Context ì¡°í•©
        context = f"""
        [ê²€ìƒ‰ëœ {year}ë…„ë„ ì „ê¸°ê³µí•™ê³¼ ì·¨ì—… í†µê³„]
        
        1. ì „ì²´ í˜„í™©
        {overall_text}
        
        2. ê¸°ì—… í˜•íƒœë³„ ë¶„í¬
        - {dist_text}
        
        3. ì£¼ìš” ì·¨ì—…ì²˜ ìƒì„¸ (ê¸°ì—…ëª… ë° ì¸ì›)
        - ğŸ¢ ëŒ€ê¸°ì—…: {large_ent}
        - ğŸ­ ì¤‘ê²¬ê¸°ì—…: {medium_ent}
        - ğŸ˜ï¸ ì¤‘ì†Œê¸°ì—…: {small_ent}
        - ğŸ›ï¸ ê³µê³µê¸°ê´€/ê³µê¸°ì—…: {public_inst}
        """
        
        return context

    except Exception as e:
        print(f"ì·¨ì—… í†µê³„ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        traceback.print_exc()
        return "ì·¨ì—… í†µê³„ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."